{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n#Load the modules\nfrom glob import glob \nimport numpy as np\nimport pandas as pd\nimport keras,cv2,os\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\nfrom keras.layers import Conv2D, MaxPool2D\n\nfrom tqdm import tqdm_notebook,trange\nimport matplotlib.pyplot as plt\n\nimport gc #garbage collection, we need to save all the RAM we can\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n#\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load the labels（0表示没有癌细胞（负样本），1表示有（正样本）） and filenames"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#set paths to training and test data\npath = \"../input/\" #adapt this path, when running locally\ntrain_path = path + 'train/'\ntest_path = path + 'test/'\n\ndf = pd.DataFrame({'path': glob(os.path.join(train_path,'*.tif'))}) # load the filenames\ndf['id'] = df.path.map(lambda x: x.split('/')[3].split(\".\")[0]) # keep only the file names in 'id'\nlabels = pd.read_csv(path+\"train_labels.csv\") # read the provided labels\ndf = df.merge(labels, on = \"id\") # merge labels and filepaths\ndf.head(3) # print the first three entrys","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load the images"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(N,df):\n    \"\"\" This functions loads N images using the data df\n    \"\"\"\n    # allocate a numpy array for the images (N, 96x96px, 3 channels, values 0 - 255)\n    X = np.zeros([N,96,96,3],dtype=np.uint8) \n    #convert the labels to a numpy array too\n    y = np.squeeze(df.as_matrix(columns=['label']))[0:N]\n    #read images one by one, tdqm notebook displays a progress bar\n    for i, row in tqdm_notebook(df.iterrows(), total=N):\n        if i == N:\n            break\n        X[i] = cv2.imread(row['path'])\n          \n    return X,y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load 10k images first\nN=10000\nX,y = load_data(N=N,df=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploratory Data Analysis (EDA)  \n1. 看一下图片\n2. 了解两种类别的分布情况\n3. 看一下特征（比如RGB channel的分布，平均亮度）"},{"metadata":{},"cell_type":"markdown","source":"some example images  \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10, 4), dpi=150)\nnp.random.seed(100) #we can use the seed to get a different set of random images\nfor plotNr,idx in enumerate(np.random.randint(0,N,8)):\n    ax = fig.add_subplot(2, 8//2, plotNr+1, xticks=[], yticks=[]) #add subplots\n    plt.imshow(X[idx]) #plot image\n    ax.set_title('Label: ' + str(y[idx])) #show the label corresponding to the image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"看一下图片可以让我们先对两种类别有一个大概的了解，这对于后面选择什么特征作为分类依据很重要"},{"metadata":{},"cell_type":"markdown","source":"the data distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(4, 2),dpi=150)\nplt.bar([1,0], [(y==0).sum(), (y==1).sum()]); #plot a bar chart of the label frequency\nplt.xticks([1,0],[\"Negative (N={})\".format((y==0).sum()),\"Positive (N={})\".format((y==1).sum())]);\nplt.ylabel(\"# of samples\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"可以看出，在训练集中负样本多于正样本，且正负比例近似为2：3.也就是全部判定为没有癌症细胞也能有60%的准确性，这可能导致分类器偏向于负样本。为了避免分类器中的偏差并改善训练期间的稳定性，我们可以采取过采样和欠采样"},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_samples = X[y == 1]\nnegative_samples = X[y == 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"compare the distribution of pixel values for each color channel (RGB) individually and all channels together"},{"metadata":{"trusted":true},"cell_type":"code","source":"nr_of_bins = 256 #each possible pixel value will get a bin in the following histograms\nfig,axs = plt.subplots(4,2,sharey=True,figsize=(8,8),dpi=150)\n\n#RGB channels\naxs[0,0].hist(positive_samples[:,:,:,0].flatten(),bins=nr_of_bins,density=True)\naxs[0,1].hist(negative_samples[:,:,:,0].flatten(),bins=nr_of_bins,density=True)\naxs[1,0].hist(positive_samples[:,:,:,1].flatten(),bins=nr_of_bins,density=True)\naxs[1,1].hist(negative_samples[:,:,:,1].flatten(),bins=nr_of_bins,density=True)\naxs[2,0].hist(positive_samples[:,:,:,2].flatten(),bins=nr_of_bins,density=True)\naxs[2,1].hist(negative_samples[:,:,:,2].flatten(),bins=nr_of_bins,density=True)\n\n#All channels\naxs[3,0].hist(positive_samples.flatten(),bins=nr_of_bins,density=True)\naxs[3,1].hist(negative_samples.flatten(),bins=nr_of_bins,density=True)\n\n#Set image labels\naxs[0,0].set_title(\"Positive samples (N =\" + str(positive_samples.shape[0]) + \")\");\naxs[0,1].set_title(\"Negative samples (N =\" + str(negative_samples.shape[0]) + \")\");\naxs[0,1].set_ylabel(\"Red\",rotation='horizontal',labelpad=35,fontsize=12)\naxs[1,1].set_ylabel(\"Green\",rotation='horizontal',labelpad=35,fontsize=12)\naxs[2,1].set_ylabel(\"Blue\",rotation='horizontal',labelpad=35,fontsize=12)\naxs[3,1].set_ylabel(\"RGB\",rotation='horizontal',labelpad=35,fontsize=12)\nfor i in range(4):\n    axs[i,0].set_ylabel(\"Relative frequency\")\naxs[3,0].set_xlabel(\"Pixel value\")\naxs[3,1].set_xlabel(\"Pixel value\")\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. 与正样本相比，负样本像素更多在高亮度部分，特别是在绿通道中  \n2. 正样本中，相比于其他两通道，绿通道中的像素更暗。而负样本不是这样\n3. 正负样本中都存在大部分亮白色区域"},{"metadata":{},"cell_type":"markdown","source":"take the mean of each individual image and look at that distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"nr_of_bins = 64 #we use a bit fewer bins to get a smoother image\nfig,axs = plt.subplots(1,2,sharey=True, sharex = True, figsize=(8,2),dpi=150)\naxs[0].hist(np.mean(positive_samples,axis=(1,2,3)),bins=nr_of_bins,density=True);\naxs[1].hist(np.mean(negative_samples,axis=(1,2,3)),bins=nr_of_bins,density=True);\naxs[0].set_title(\"Mean brightness, positive samples\");\naxs[1].set_title(\"Mean brightness, negative samples\");\naxs[0].set_xlabel(\"Image mean brightness\")\naxs[1].set_xlabel(\"Image mean brightness\")\naxs[0].set_ylabel(\"Relative frequency\")\naxs[1].set_ylabel(\"Relative frequency\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. 正样本的平均亮度分布接近于均值为150正态分布\n2. 负样本近似双峰分布，峰值为140和225"},{"metadata":{},"cell_type":"markdown","source":"通过EDA，我们可以得到以下结论\n1. 正负样本在像素的分布和平均亮度的分布上有明显的区别，我们的模型可以利用这一点\n2. 一些图片包含了很亮的区域，可能是记录过程中的人为因素导致，我们需要找到一种方法解决他们。他们在正负样本中都有，所以不能简单当作一个特征\n3. 负样本多于正样本很多，可能需要调整"},{"metadata":{},"cell_type":"markdown","source":"loading all the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"N = df[\"path\"].size # get the number of images in the training data set\nX,y = load_data(N=N,df=df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"free up space in our RAM"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Collect garbage\npositives_samples = None\nnegative_samples = None\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"split the data into a training and validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"training_portion = 0.8 # Specify training/validation ratio\nsplit_idx = int(np.round(training_portion * y.shape[0])) #Compute split idx\n\nnp.random.seed(42) #set the seed to ensure reproducibility\n\n#shuffle\nidx = np.arange(y.shape[0])\nnp.random.shuffle(idx)\nX = X[idx]\ny = y[idx]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"neural network architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"#just some network parameters, see above link regarding the layers for details\nkernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 32\nsecond_filters = 64\nthird_filters = 128\n\n#dropout is used for regularization here with a probability of 0.3 for conv layers, 0.5 for the dense layer at the end\ndropout_conv = 0.3\ndropout_dense = 0.5\n\n#initialize the model\nmodel = Sequential()\n\n#now add layers to it\n\n#conv block 1 （卷积层）\nmodel.add(Conv2D(first_filters, kernel_size, input_shape = (96, 96, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(first_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\n#conv block 2 （batch normalization）\nmodel.add(Conv2D(second_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(second_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\n#conv block 3 （pooling and dropout）\nmodel.add(Conv2D(third_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Conv2D(third_filters, kernel_size, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPool2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\n#a fully connected (also called dense) layer at the end\nmodel.add(Flatten())\nmodel.add(Dense(256, use_bias=False))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(dropout_dense))\n\n#finally convert to values of 0 to 1 using the sigmoid activation function\nmodel.add(Dense(1, activation = \"sigmoid\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"compile  \n配置模型训练时的参数"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 50\n\nmodel.compile(loss=keras.losses.binary_crossentropy,\n              optimizer=keras.optimizers.Adam(0.001), \n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"batch size是训练一个神经网络是很关键的参数。在训练的时候，我们将训练集分成一个个的batch，然后用batch一个个的去训练我们的网络"},{"metadata":{},"cell_type":"markdown","source":"Train and validate the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#normally you would want to reshuffle the data between epochs, we don't as we split in-place into training/validation\nepochs = 3 #how many epochs we want to perform（代表每一张图片上训练三次）\nfor epoch in range(epochs):\n    #compute how many batches we'll need\n    iterations = np.floor(split_idx / batch_size).astype(int) #the floor makes us discard a few samples here, I got lazy...\n    loss,acc = 0,0 #we will compute running loss and accuracy\n    with trange(iterations) as t: #display a progress bar\n        for i in t:\n            start_idx = i * batch_size #starting index of the current batch\n            x_batch = X[start_idx:start_idx+batch_size] #the current batch\n            y_batch = y[start_idx:start_idx+batch_size] #the labels for the current batch\n\n            metrics = model.train_on_batch(x_batch, y_batch) #train the model on a batch\n\n            loss = loss + metrics[0] #compute running loss\n            acc = acc + metrics[1] #compute running accuracy\n            t.set_description('Running training epoch ' + str(epoch)) #set progressbar title\n            t.set_postfix(loss=\"%.2f\" % round(loss / (i+1),2),acc=\"%.2f\" % round(acc / (i+1),2)) #display metrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create a submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = None\ny = None\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_test_dir = path + 'test/' #specify test data folder\ntest_files = glob(os.path.join(base_test_dir,'*.tif')) #find the test file names\nsubmission = pd.DataFrame() #create a dataframe to hold results\nfile_batch = 5000 #we will predict 5000 images at a time\nmax_idx = len(test_files) #last index to use\nfor idx in range(0, max_idx, file_batch): #iterate over test image batches\n    print(\"Indexes: %i - %i\"%(idx, idx+file_batch))\n    test_df = pd.DataFrame({'path': test_files[idx:idx+file_batch]}) #add the filenames to the dataframe\n    test_df['id'] = test_df.path.map(lambda x: x.split('/')[3].split(\".\")[0]) #add the ids to the dataframe\n    test_df['image'] = test_df['path'].map(cv2.imread) #read the batch\n    K_test = np.stack(test_df[\"image\"].values) #convert to numpy array\n    predictions = model.predict(K_test,verbose = 1) #predict the labels for the test data\n    test_df['label'] = predictions #store them in the dataframe\n    submission = pd.concat([submission, test_df[[\"id\", \"label\"]]])\nsubmission.head() #display first lines","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index = False, header = True) #create the submission file","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}